{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2fbdd2d",
   "metadata": {},
   "source": [
    "1. import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d37583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import \n",
    "%run 0_function.ipynb\n",
    "# from function import yyplot_k, search_highly_correlated_variables_cv, boruta_cv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6376551",
   "metadata": {},
   "source": [
    "2. Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730f881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed\n",
    "rseed_cv = 42\n",
    "rseed_boruta = 1\n",
    "rseed_model = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964c3370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select dataset, monomer, descriptors\n",
    "data_set = \"1&2\" #1&2\n",
    "monomer = \"St\" #St or nBA\n",
    "descriptors = \"Mordred\" #morganFP, RDKit, Mordred, mechanism_oriented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc5ec13",
   "metadata": {},
   "source": [
    "3. Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de6cef6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet 'St' not found. Loading the first sheet instead.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # file & preprocessing\n",
    "    try:     \n",
    "        df_X = pd.read_excel(\"../data/XY/data_set_{}/data_set_{}_{}_descriptors.xlsx\".format(data_set, data_set, descriptors), index_col = 0, sheet_name = monomer) #descriptors select\n",
    "    except ValueError:\n",
    "        print(f\"Sheet '{monomer}' not found. Loading the first sheet instead.\")\n",
    "        df_X = pd.read_excel(\"../data/XY/data_set_{}/data_set_{}_{}_descriptors.xlsx\".format(data_set, data_set, descriptors), index_col = 0)\n",
    "        \n",
    "    df_Y = pd.read_excel(\"../data/XY/data_set_{}/data_set_{}_SMILES&objective_function.xlsx\".format(data_set, data_set), index_col = 0)\n",
    "    \n",
    "    df = pd.concat([df_X, df_Y], axis=1)\n",
    "    \n",
    "    df.index = df.index.astype(\"str\")\n",
    "    X = df.iloc[:, :len(df_X.columns)]\n",
    "    y = np.log(df[\"{}_PDI\".format(monomer)]-1) # St_PDI or nBA_PDI\n",
    "    \n",
    "    fold = len(df.index)\n",
    "    kf = KFold(n_splits=fold, shuffle=True, random_state=rseed_cv)\n",
    "    n_estimators = np.arange(1, 105, 5)\n",
    "    params  = dict(n_estimators = n_estimators)\n",
    "    scoring     = make_scorer(RMSE, greater_is_better = False)\n",
    "    model = GridSearchCV(RandomForestRegressor(), param_grid=params, scoring=scoring, cv=fold-1)\n",
    "\n",
    "       \n",
    "    CV_results = pd.DataFrame(index = X.index, columns = ['inner_R2', 'pred_y', 'observed_y', \"top10_features\", \"top10_coefficients\"])\n",
    "    \n",
    "    for perc in [80, 90, 100]:\n",
    "        for ifold, (tridx, tsidx) in enumerate(kf.split(X, y)):\n",
    "            try:\n",
    "                Xtr, Xts = X.iloc[tridx], X.iloc[tsidx]\n",
    "                ytr, yts = y.iloc[tridx], y.iloc[tsidx]\n",
    "                \n",
    "                Xtr, Xts = search_highly_correlated_variables_cv(Xtr, Xts, 0.8)\n",
    "                Xtr, Xts = boruta_cv(Xtr, ytr, Xts, perc = perc, rseed_boruta = rseed_boruta) # select the best perc \n",
    "                \n",
    "                #No standardization when using morganFP \n",
    "                scaler_X = StandardScaler()\n",
    "                scaler_X.fit(Xtr)\n",
    "                Xtr = pd.DataFrame(scaler_X.transform(Xtr), index = Xtr.index, columns = Xtr.columns)\n",
    "                Xts = pd.DataFrame(scaler_X.transform(Xts), index = Xts.index, columns = Xts.columns)\n",
    "            \n",
    "                model.fit(Xtr, ytr)\n",
    "                model_inner = RandomForestRegressor(n_estimators = model.best_params_['n_estimators'])\n",
    "                model_inner.fit(Xtr, ytr)\n",
    "                ytr_pred = model_inner.predict(Xtr)\n",
    "                yts_pred = model_inner.predict(Xts)\n",
    "                \n",
    "                coefficients = model_inner.feature_importances_.ravel()\n",
    "                top10_features = np.argsort(np.abs(coefficients))[::-1][:10].tolist()\n",
    "                top10_coefficients = [round(num, 2) for num in coefficients[top10_features].tolist()]\n",
    "                \n",
    "                CV_results.loc[Xts.index, \"inner_R2\"] = r2_score(np.exp(ytr) + 1, np.exp(ytr_pred) + 1)\n",
    "                CV_results.loc[Xts.index, 'pred_y'] = np.exp(yts_pred) + 1\n",
    "                CV_results.loc[Xts.index, 'observed_y'] = np.exp(yts) + 1\n",
    "                CV_results.loc[Xts.index, 'top10_features'] = str(top10_features)\n",
    "                CV_results.loc[Xts.index, 'top10_coefficients'] = str(top10_coefficients)\n",
    "            \n",
    "            except ValueError as e:\n",
    "                print(\"An error occurred:\", e, \"Because the number of descriptors was set to zero by Boruta\")    \n",
    "                sys.exit(1)\n",
    "        \n",
    "        dirname = \"../result/LOOCV/RF/\"\n",
    "        os.makedirs(dirname, exist_ok = True)\n",
    "        \n",
    "        CV_results.to_excel(dirname + \"/{}_{}_RF_LOOCV_{}_perc={}.xlsx\".format(data_set, monomer, descriptors, perc))\n",
    "        \n",
    "    \n",
    "        # valuation index\n",
    "        r2 = r2_score(CV_results['observed_y'], CV_results['pred_y'])\n",
    "        MAE = mean_absolute_error(CV_results['observed_y'], CV_results['pred_y'])\n",
    "        \n",
    "        # # ## 予測結果の図示\n",
    "        yyplot_k(CV_results['observed_y'], CV_results['pred_y'])\n",
    "        \n",
    "        for i, label in enumerate (CV_results.index):\n",
    "            plt.annotate(label, xy = (CV_results['observed_y'][label], CV_results['pred_y'][label]), xytext=(0, 5),  # Adjust these values as needed\n",
    "                textcoords='offset points',size =8, color = \"steelblue\")\n",
    "            \n",
    "        plt.text(0.05, 0.95, r\"$R^2$={}, MAE={}\".format(round(r2, 2), round(MAE, 3)), transform=plt.gca().transAxes,\n",
    "                  verticalalignment='top', horizontalalignment='left',\n",
    "                  bbox=dict(facecolor='white', edgecolor='none', alpha=0.5))\n",
    "        \n",
    "           \n",
    "        plt.savefig(dirname + \"/{}_{}_RF_LOOCV_{}_perc={}.jpg\".format(data_set, monomer, descriptors, perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f6fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
